# vim: set ft=yaml:

groups:
- name: openstack-keppel-api.alerts
  rules:

  - alert: OpenstackKeppelDown
    expr: keppel_healthmonitor_result != 1 or absent(keppel_healthmonitor_result)
    for: 3m
    labels:
      context: api
      dashboard: keppel-overview
      service: keppel
      severity: warning # TODO raise to critical at some point
      tier: os
      meta: 'Keppel health check is not reporting success'
      playbook: docs/support/playbook/keppel/down
    annotations:
      summary: Keppel health check is not reporting success.
      description: |
        Keppel health check is not reporting success. Check that the
        "keppel-health-monitor" pod in the Kubernetes namespace "keppel" is
        running, and if so, check its log for error messages.

  - alert: OpenstackKeppelSlowPeering
    expr: time() - keppel_peers_last_peered_at > 1800
    for: 5m
    labels:
      context: api
      dashboard: keppel-overview
      service: keppel
      severity: info
      tier: os
      meta: 'Keppel cannot peer with {{ $labels.hostname }}'
    annotations:
      summary: 'Keppel cannot peer with {{ $labels.hostname }}'
      description: |
        The Keppel instance in this region should check in with its peer
        {{ $labels.hostname }} every 10 minutes, but it has not done so in
        the last 30 minutes. The logs of the keppel-api pods should contain
        additional information or error messages.

  - alert: OpenstackKeppelSlowBlobReplication
    expr: keppel_blob_replication_min_started_at > 0 and time() - keppel_blob_replication_min_started_at > 900
    for: 5m
    labels:
      context: api
      dashboard: keppel-overview
      service: keppel
      severity: info
      tier: os
      meta: 'Blob replication is taking a long time'
    annotations:
      summary: 'Blob replication is taking a long time'
      description: |
        A blob replication has been running in this Keppel instance for more
        than 15 minutes. This could indicate that the region interconnect is slow.

  - alert: OpenstackKeppelDBConnectionPoolNearlyFull
    expr: avg_over_time(go_sql_stats_connections_in_use{db_name="keppel"}[1h]) > 8
    for: 5m
    labels:
      context: dbconnpool
      dashboard: keppel-overview
      service: keppel
      severity: info
      tier: os
      meta: 'DB connection pool nearly full on {{ $labels.pod }}'
    annoatations:
      summary: 'DB connection pool nearly full on {{ $labels.pod }}'
      description: |
        The DB connection pool on pod {{ $labels.pod }} is filling up. It can
        go up to 16 connections, but during regular operations we should not go
        over 3-5 connections to retain some budget for request spikes. Going
        high on connections for a long time indicates that the pod might be
        starved for CPU time, so try checking the CPU throttling metrics.
