curator:
  configMaps:
    config_yml: |-
      ---
      client:
        hosts:
          - elasticsearch-data
        port: 9200
    # Delete indices older than 3 months
    action_file_yml: |-
      ---
      actions:
        1:
          action: delete_indices
          description: "Clean up ES by deleting old indices"
          options:
            timeout_override:
            continue_if_exception: False
            disable_action: False
            ignore_empty_list: True
            allow_ilm_indices: True
          filters:
          - filtertype: pattern
            kind: prefix
            value: .kibana
            exclude: True
          - filtertype: pattern
            kind: prefix
            value: .task
            exclude: True
          - filtertype: age
            source: name
            direction: older
            timestring: '%Y.%m.%d'
            unit: months
            unit_count: 3
            field:
            stats_result:
            epoch:
            exclude: False
        2:
          action: delete_indices
          description: "Delete indices before disk is full. 85G on 100G PVCs"
          options:
            timeout_override:
            continue_if_exception: False
            disable_action: False
            ignore_empty_list: True
            allow_ilm_indices: True
          filters:
          - filtertype: pattern
            kind: prefix
            value: .kibana
            exclude: True
          - filtertype: pattern
            kind: prefix
            value: .task
            exclude: True
          - filtertype: space
            disk_space: 1250
            use_age: True
            source: creation_date
            exclude:
          - filtertype: kibana
            exclude: True

# master node configs
elasticsearch:
  enabled: true
  image: "docker.elastic.co/elasticsearch/elasticsearch"

  roles:
    master: "true"
    ingest: "false"
    data: "false"
    
  esJavaOpts: "-Xmx4G -Xms4G"
  esConfig:
    elasticsearch.yml: |
      indices.query.bool.max_clause_count: 8192
      search.max_buckets: 100000

  volumeClaimTemplate:
    accessModes: [ "ReadWriteMany" ]
    resources:
      requests:
        storage: 1G

  resources:
    requests:
      memory: "4G"
    limits:
      memory: "6G"

  extraInitContainers: |
    - name: configure-ownership
      securityContext:
        runAsUser: 0
        privileged: true
      image: "{{ .Values.image }}:{{ .Values.imageTag }}"
      imagePullPolicy: "{{ .Values.imagePullPolicy }}"
      command: ["sh", "-c", "mkdir -p /usr/share/elasticsearch/data && chown -R 1000:1000 /usr/share/elasticsearch/data"]
      volumeMounts:
        - name: "{{ template "elasticsearch.uname" . }}"
          mountPath: /usr/share/elasticsearch/data

elasticsearch-data:
  nodeGroup: data
  masterService: elasticsearch-master
  roles:
    master: "false"
    ingest: "true"
    data: "true"
  replicas: 2
  esJavaOpts: "-Xmx4G -Xms4G"
  esConfig:
    elasticsearch.yml: |
      indices.query.bool.max_clause_count: 8192
      search.max_buckets: 100000
  volumeClaimTemplate:
    accessModes: [ "ReadWriteMany" ]
    resources:
      requests:
        storage: 500G
  resources:
    requests:
      memory: "4G"
    limits:
      memory: "6G"
    
  extraInitContainers: |
    - name: configure-ownership
      securityContext:
        runAsUser: 0
        privileged: true
      image: "{{ .Values.image }}:{{ .Values.imageTag }}"
      imagePullPolicy: "{{ .Values.imagePullPolicy }}"
      command: ["sh", "-c", "mkdir -p /usr/share/elasticsearch/data && chown -R 1000:1000 /usr/share/elasticsearch/data"]
      volumeMounts:
        - name: "{{ template "elasticsearch.uname" . }}"
          mountPath: /usr/share/elasticsearch/data

elasticsearchExporter:
  name: elastiflow
  enabled: true
  image: 
    repo: justwatch/elasticsearch_exporter
    tag: 1.1.0
  es:
    uri: http://elasticsearch-master:9200
  listen_port: 9102
  targets: prometheus-openstack
  
logstash:
  image: "elastiflow-logstash"
  imageTag: "DEFINED-IN-PIPELINE"
  logstashJavaOpts: "-Xmx4G -Xms4G"

  persistence:
    enabled: false

  resources:
    requests:
      cpu: 500m
      memory: 4G
    limits:
      cpu: 4000m
      memory: 6G

  extraEnvs:
    - name: ELASTIFLOW_ES_HOST
      value: "elasticsearch-master:9200"
  jdbc:
    enabled: false
    configMap: "jdbc-filter"
    configFile: "20_filter_95_enrich_ips.conf"
  service:
    type: NodePort
    ports:
      - name: netflow-udp
        port: 2055
        targetPort: 2055
        nodePort: 30055
        protocol: UDP
      - name: sflow-udp
        port: 6343
        targetPort: 6343
        nodePort: 30343
        protocol: UDP
      - name: ipfix-udp
        port: 4739
        targetPort: 4739
        nodePort: 30739
        protocol: UDP
      - name: ipfix-tcp
        port: 4739
        targetPort: 4739
        nodePort: 30740
        protocol: TCP
      - name: http
        port: 9600
        targetPort: 9600
        protocol: TCP

  readinessProbe:
    # use ipfix-tcp port instead of http API to better check elastiflow specific status
    httpGet: null
    tcpSocket:
      port: 4739
    initialDelaySeconds: 300
    periodSeconds: 30
    failureThreshold: 20
    successThreshold: 1

  livenessProbe:
    httpGet: null
    tcpSocket:
      port: 4739
    initialDelaySeconds: 600
    periodSeconds: 20
    failureThreshold: 5
    successThreshold: 1

logstashExporter:
  name: elastiflow
  enabled: false
  image: 
    repo: bonniernews/logstash_exporter
    tag: v0.1.2
  ls:
    uri: http://elastiflow-logstash:9600
  listen_port: 9198
  targets: prometheus-openstack

kibana:
  image: "docker.elastic.co/kibana/kibana"
  elasticsearchHosts: "http://elasticsearch-master:9200"

# Deploy Prometheus alerts.
alerts:
  enabled: true
  # Name of the Prometheus to which the alerts should be assigned to.
  prometheus: openstack

queryExporter:
  name: elastiflow
  enabled: true
  image:
    repo: braedon/prometheus-es-exporter
    tag: 0.9.0
  es:
    uri: "http://elasticsearch-master:9200"
  listen_port: 9206
  targets: prometheus-openstack
  config:
    exporter.cfg: |
      [DEFAULT]
      QueryIntervalSecs = 15
      QueryTimeoutSecs = 10
      QueryIndices = _all
      QueryOnError = drop
      QueryOnMissing = drop

      [query_all]
      QueryJson = {"size": 0, "query": {"match_all": {}}}
